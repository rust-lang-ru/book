## Превращение однопоточного отдельного вычислителя в многопоточный отдельный вычислитель

В текущей выполнения отдельный вычислитель обрабатывает каждый запрос по очереди, то есть, он не начнёт обрабатывать второе соединение, пока не завершит обработку первого. При росте числа запросов к отдельному вычислителю, такое последовательное выполнение было бы все менее и менее разумным. Если отдельный вычислитель получает какой-то запрос, обработка которого занимает достаточно много времени, последующим запросам придётся ждать завершения обработки длительного запроса, даже если эти новые запросы сами по себе могут быть обработаны быстро. Нам нужно это исправить, но сначала рассмотрим неполадку в действии.

### Подражание медленного запроса в текущей выполнения отдельного вычислителя

Мы посмотрим, как запрос с медленной обработкой может повлиять на другие запросы, сделанные к отдельному вычислителю в текущей выполнения. В приложении 20-10 выполнена обработка запроса к источнику */sleep* с эмуляцией медленного ответа, при которой отдельный вычислитель будет ждать 5 секунд перед тем, как ответить.

<span class="filename">Файл: src/main.rs</span>

```rust,no_run
{{#rustdoc_include ../listings/ch20-web-server/listing-20-10/src/main.rs:here}}
```

<span class="caption">Приложение 20-10: Подражание медленного запроса с помощью 5-секундной задержки</span>

Мы переключились с `if` на `match`, так как теперь у нас есть три случая. Нам придётся явно сопоставить срез от `request_line` для проверки совпадения образца данных со строковыми записями; `match` не делает самостоятельно е ссылки и разыменования, как это делает способ равенства.

Первая ветка совпадает с разделом `if` из приложения 20-9. Вторая ветка соответствует запросу */sleep* . Когда этот запрос получен, отдельный вычислитель заснёт на 5 секунд, прежде чем отдать успешную HTML-страницу. Третья ветка совпадает с разделом `else` из приложения 20-9.

Можно увидеть, насколько прост наш отдельный вычислитель: в существующих библиотеках распознавание разных запросов осуществлялось бы гораздо менее многословно!

Запустите отдельный вычислитель приказом `cargo run`. Затем откройте два окна обозревателя: одно с адресом *http://127.0.0.1:7878/*, другое с *http://127.0.0.1:7878/sleep*. Если вы несколько раз обратитесь к URI */*, то как и раньше увидите, что отдельный вычислитель быстро ответит. Но если вы введёте URI */sleep*, а затем загрузите URI */*, то увидите что */* ждёт, пока `/sleep` не отработает полные 5 секунд перед загрузкой страницы.

Есть несколько способов, которые можно использовать, чтобы избавиться от подтормаживания запросов после одного медленного запроса; способ, который мы выполняем, называется объединением потоков.

### Улучшение пропускной способности с помощью объединения потоков

*Объединение потоков* является объединением заранее порождённых потоков, ожидающих в объединении и готовых выполнить задачу. Когда программа получает новую задачу, она назначает эту задачу одному из потоков в объединении, и тогда задача будет обработана этим потоком. Остальные потоки в объединении доступны для обработки любых других задач, поступающих в то время, пока первый поток занят. Когда первый поток завершает обработку своей задачи, он возвращается в объединение свободных потоков, готовых приступить к новой задаче. Объединение потоков позволяет обрабатывать соединения одновременно, увеличивая пропускную способность вашего отдельного вычислителя.

Мы ограничим число потоков в объединении небольшим числом, чтобы защитить нас от нападений вида «отказ в обслуживании» (DoS - Denial of Service); если бы наша программа создавала новый поток в мгновение поступления каждого запроса, то кто-то сделавший 10 миллионов запросов к отдельному вычислителю, мог бы создать разгром, использовать все мощности нашего отдельного вычислителя и остановить обработку запросов.

Вместо порождения неограниченного количества потоков, у нас будет определенное количество потоков, ожидающих в объединении. Поступающие запросы будут отправляться в объединение для обработки. Объединение будет иметь очередь входящих запросов. Каждый из потоков в объединении будет извлекать запрос из этой очереди, обрабатывать запрос и затем запрашивать в очереди следующий запрос. При таком внешнем виде мы можем обрабатывать `N` запросов одновременно, где `N` - количество потоков. Если каждый поток отвечает на длительный запрос, последующие запросы могут по-прежнему задержаться в очереди, но теперь мы увеличили количество "длинных" запросов, которые мы можем обработать, перед тем, как эта случай снова возникнет.

Этот подход - лишь один из многих способов улучшить пропускную способность сетевого-отдельного вычислителя. Другими исходами, на которые возможно стоило бы обратить внимание, являются: *прообраз fork/join*, *прообраз однопоточного не согласованного ввода-вывода* или *прообраз многопоточного не согласованного ввода-вывода*. Если вам важен этот вопрос, вы можете почитать больше сведений о других решениях и попробовать выполнить их самостоятельно. С таким низкоуровневым языком как Ржавчина, любой из этих исходов осуществим.

Прежде чем приступить к выполнения объединения потоков, давайте поговорим о том, как должно выглядеть использование объединения . Когда вы пытаетесь создать рукопись, сначала необходимо написать внешнюю оболочку для конечного потребителя . Напишите API рукописи, чтобы он был внутренне выстроен так, как вы хотите его вызывать, затем выполните возможность данного устройства, вместо подхода использовать возможности, а затем разрабатывать общедоступный API.

Подобно тому, как мы использовали разработку через проверку (test-driven) в деле Главы 12, мы будем использовать здесь разработку, управляемую сборщиком (compiler-driven). Мы напишем рукопись, вызывающую нужные нам функции, а затем посмотрим на ошибки сборщика, чтобы определить, что мы должны изменить дальше, чтобы заставить рукопись работать. Однако перед этим, в качестве отправной точки, мы рассмотрим технику, которую мы не будем применять в дальнейшем.

<!-- Old headings. Do not remove or links may break. -->

<a id="code-structure-if-we-could-spawn-a-thread-for-each-request"></a>

#### Порождение потока для каждого запроса

Сначала давайте рассмотрим, как могла бы выглядеть рукопись, если бы она создавал бы новый поток для каждого соединения. Как упоминалось ранее, мы не собираемся использовать этот способ в окончательном исолнении, из-за возможных неполадок при возможно неограниченном числе порождённых потоков. Это лишь отправная точка, с которой начнёт работу наш многопоточный отдельный вычислитель. Затем мы улучшим рукопись, добавив объединение потоков, и тогда разницу между этими двумя решениями будет легче заметить. В приложении 20-11 показаны изменения, которые нужно внести в рукопись `main`, чтобы порождать новый поток для обработки каждого входящего соединения внутри круговорота `for`.

<span class="filename">Файл: src/main.rs</span>

```rust,no_run
{{#rustdoc_include ../listings/ch20-web-server/listing-20-11/src/main.rs:here}}
```

<span class="caption">Приложение 20-11: Порождение нового потока для каждого соединения</span>

Как вы изучили в главе 16, функция `thread::spawn` создаст новый поток и затем запустит рукопись замыкания в этом новом потоке. Если вы запустите эту рукопись и загрузите */sleep* в своём обозревателе, а затем загрузите */* в двух других вкладках обозревателя, вы действительно увидите, что запросам к */* не приходится ждать завершения */sleep*. Но, как мы уже упоминали, это в какое-то мгновение приведёт к сильному снижению производительности системы, так как вы будете создавать новые потоки без каких-либо ограничений.

<!-- Old headings. Do not remove or links may break. -->

<a id="creating-a-similar-interface-for-a-finite-number-of-threads"></a>

#### Создание конечного числа потоков

Мы хотим, чтобы наш объединение потоков работал подобным, знакомым образом, чтобы переключение с потоков на объединение потоков не требовало больших изменений в рукописи использующем наш API. В приложении 20-12 показан гипотетический внешняя оболочка для вида данных `ThreadPool`, который мы хотим использовать вместо `thread::spawn`.

<span class="filename">Файл: src/main.rs</span>

```rust,ignore,does_not_compile
{{#rustdoc_include ../listings/ch20-web-server/listing-20-12/src/main.rs:here}}
```

<span class="caption">Приложение 20-12: Наш наилучший внешняя оболочка <code>ThreadPool</code></span>

Мы используем `ThreadPool::new`, чтобы создать новое объединение потоков с настраиваемым числом потоков, в данном случае четырьмя. Затем в круговороте `for` функция `pool.execute` имеет внешнюю оболочку, похожий на `thread::spawn`, в том смысле, что он так же принимает замыкание, которое рукопись (объединение) должна выполнить для каждого соединения. Нам нужно использовать `pool.execute`, чтобы он принимал замыкание и передавал его потоку из объединения для выполнения. Эта рукопись пока не собирается, но мы постараемся, чтобы сборщик помог нам это исправить.

<!-- Old headings. Do not remove or links may break. -->

<a id="building-the-threadpool-struct-using-compiler-driven-development"></a>

#### Создание `ThreadPool` с помощью разработки, управляемой сборщиком

Внесите изменения приложения 20-12 в файл *src/main.rs*, а затем давайте воспользуемся ошибками сборщика из приказы `cargo check` для управления нашей разработкой. Вот первая ошибка, которую мы получаем:

```console
{{#include ../listings/ch20-web-server/listing-20-12/output.txt}}
```

Замечательно! Ошибка говорит о том, что нам нужен вид данных или раздел `ThreadPool`, поэтому мы сейчас его создадим. Наша использование `ThreadPool` не будет зависеть от того, что делает наш сетевой-отдельный вычислитель. Итак, давайте переделаем ящик `hello` из двоичного в библиотечный, чтобы хранить там нашу использование `ThreadPool`. После того, как мы переключимся в библиотечный ящик, мы также сможем использовать отдельную библиотеку объединения потоков для любой подходящей работы, а не только для обслуживания сетевых-запросов.

Создайте файл *src/lib.rs*, который содержит следующую рукопись, которая является простейшим определением вида данных `ThreadPool`, которое мы можем иметь на данное мгновение:

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/no-listing-01-define-threadpool-struct/src/lib.rs}}
```

Затем изменените файл *main.rs*, чтобы внести `ThreadPool`  из библиотечного ящика в текущую область видимости, добавив следующую рукопись в начало *src/main.rs*:

<span class="filename">Файл: src/main.rs</span>

```rust,ignore
{{#rustdoc_include ../listings/ch20-web-server/no-listing-01-define-threadpool-struct/src/main.rs:here}}
```

Эта рукопись по-прежнему не будет работать, но давайте проверим его ещё раз, чтобы получить следующую ошибку, которую нам нужно устранить:

```console
{{#include ../listings/ch20-web-server/no-listing-01-define-threadpool-struct/output.txt}}
```

Эта ошибка указывает, что далее нам нужно создать сопряженную функцию с именем `new` для `ThreadPool`. Мы также знаем, что `new` должна иметь одно свойство, который может принимать `4` в качестве переменной и должен возвращать образец данных `ThreadPool`. Давайте выполняем простейшую функцию `new`, которая будет иметь эти свойства:

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/no-listing-02-impl-threadpool-new/src/lib.rs}}
```

Мы выбираем `usize` в качестве вида данных свойства `size`, потому что мы знаем, что отрицательное число потоков не имеет никакого смысла. Мы также знаем, что мы будем использовать число 4 в качестве количества переменных в собрании потоков, для чего предназначен вид данных `usize`, как обсуждалось в разделе ["Целочисленные виды данных"]<!--  --> Главы 3.

Давайте проверим рукопись ещё раз:

```console
{{#include ../listings/ch20-web-server/no-listing-02-impl-threadpool-new/output.txt}}
```

Теперь мы ошибка возникает из-за того, что у нас нет способа `execute` в стопке `ThreadPool`. Вспомните раздел ["Создание конечного числа потоков"](#creating-a-finite-number-of-threads)<!-- ignore -->, в котором мы решили, что наш объединение потоков должно иметь внешнюю оболочку, похожий на `thread::spawn`. Кроме того, мы выполняем функцию `execute`, чтобы она принимала замыкание и передавала его свободному потоку из объединения для запуска.

Мы определим способ `execute` у `ThreadPool`, принимающий замыкание в качестве свойства. Вспомните из раздела ["Перемещение захваченных значений из замыканий и сущности `Fn`"](ch13-01-closures.html#moving-captured-values-out-of-the-closure-and-the-fn-traits) <!-- ignore --> Главы 13 сведения о том, что мы можем принимать замыкания в качестве свойств тремя различными сущностями: `Fn` , `FnMut` и `FnOnce`. Нам нужно решить, какой вид данных замыкания использовать здесь. Мы знаем, что в конечном счёте мы сделаем что-то похожее на выполнение встроенной библиотеки `thread::spawn`, поэтому мы можем посмотреть, какие ограничения накладывает на свой свойство ярлык функции `thread::spawn`. Пособие показывает следующее:

```rust,ignore
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```

Свойство вида данных `F` - это как раз то, что нас важно; свойство вида данных `T` относится к возвращаемому значению и нам он не важен. Можно увидеть, что `spawn` использует `FnOnce` в качестве ограничения сущности у `F`. Возможно это как раз то, чего мы хотим, так как в конечном итоге мы передадим полученный в `execute` переменная в функцию `spawn`. Дополнительную уверенность в том, что `FnOnce` - это именно тот сущность, который мы хотим использовать, нам даёт обстоятельство, что поток для выполнения запроса будет выполнять замыкание этого запроса только один раз, что соответствует части  `Once` ("единожды") в названии сущности `FnOnce`.

Свойство вида данных `F` также имеет ограничение сущности `Send` и ограничение времени жизни `'static`, которые полезны в нашем случае: нам нужен `Send` для передачи замыкания из одного потока в другой и `'static`, потому что мы не знаем, сколько времени поток будет выполняться. Давайте создадим способ `execute` для `ThreadPool`, который будет принимать Обобщённое свойство вида данных `F` со следующими ограничениями:

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/no-listing-03-define-execute/src/lib.rs:here}}
```

Мы по-прежнему используем `()` после `FnOnce` потому что сущность `FnOnce` представляет замыкание, которое не принимает свойств и возвращает единичный вид данных `()`. Также как и при определении функций, вид данных возвращаемого значения в ярлыке может быть опущен, но даже если у нас нет свойств, нам все равно нужны скобки.

Опять же, это самая простая использование способа `execute`: она ничего не делает, мы просто пытаемся сделать рукопись собираемым. Давайте проверим снова:

```console
{{#include ../listings/ch20-web-server/no-listing-03-define-execute/output.txt}}
```

Сейчас мы получаем только предупреждения, что означает, что рукопись собирается! Но обратите внимание, если вы попробуете `cargo run` и сделаете запрос в обозревателе, вы увидите ошибки в обозревателе, которые мы видели в начале Главы. Наша библиотека на самом деле ещё не вызывает замыкание, переданное в `execute`!

> Примечание: вы возможно слышали высказывание о языках со строгими сборщиками, таких как Haskell и Ржавчина, которое звучит так: «Если рукопись собирается, то она работает». Но это высказывание не всегда верно. Наше дело  собирается, но безусловно ничего не делает! Если бы мы создавали существующее, законченное дело, это было бы хорошее время начать писать состоящие из разделов проверки, чтобы проверять, что рукопись собирается *и* имеет желаемое поведение.

#### Проверка количества потоков в `new`

Мы ничего не делаем с свойствами `new` и `execute`. Давайте выполняем тела этих функций с нужным нам поведением. Для начала давайте подумаем о `new`. Ранее мы выбрали беззнаковый вид данных для свойства `size`, потому что объединение с отрицательным числом потоков не имеет смысла. Объединение с нулём потоков также не имеет смысла, однако ноль - это вполне допустимое значение `usize`. Мы добавим рукопись для проверки того, что `size` больше нуля, прежде чем вернуть образец данных `ThreadPool`, и заставим программу вызвать сбой, если она получит ноль, используя макрос `assert!`, как показано в приложении 20-13.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-13/src/lib.rs:here}}
```

<span class="caption">Приложение 20-13: Выполнение <code>ThreadPool::new</code> с со сбоем завершениям работы, если <code>size</code> равен нулю</span>

Мы добавили немного пособия для нашего вида данных `ThreadPool` с помощью примечаний. Обратите внимание, что мы следовали хорошим применением документирования, добавив раздел, в котором указывается случай, при которой функция может со сбоем завершаться, как это обсуждалось в главе 14. Попробуйте запустить `cargo doc --open` и кликнуть на вид данных `ThreadPool`, чтобы увидеть как выглядит созданная пособие для `new`!

Вместо добавления макроса `assert!`, как мы здесь сделали, мы могли бы преобразовать функцию `new` в функцию `build` таким образом, чтобы она возвращала `Result` , подобно тому, как мы делали в функции `Config::new` дела ввода/вывода в приложении 12-9. Но в данном случае мы решили, что попытка создания объединения потоков без указания хотя бы одного потока должна быть непоправимой ошибкой. Если вы чувствуете такое стремление, попробуйте написать функцию `build`  с ярлыком ниже, для сравнения с функцией `new`:

```rust,ignore
pub fn build(size: usize) -> Result<ThreadPool, PoolCreationError> {
```

#### Создание места для хранения потоков

Теперь, имея возможность удостовериться, что количество потоков для хранения в объединении соответствует требованиям, мы можем создавать эти потоки и сохранять их в стопке `ThreadPool` перед тем как возвратить её. Но как мы "сохраним" поток? Давайте ещё раз посмотрим на ярлык `thread::spawn`:

```rust,ignore
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```

Функция `spawn` возвращает вид данных `JoinHandle<T>`, где `T` является видом, который возвращает замыкание. Давайте попробуем использовать `JoinHandle` и посмотрим, что произойдёт. В нашем случае замыкания, которые мы передаём объединению потоков, будут обрабатывать соединение и не будут возвращать ничего, поэтому `T` будет единичным (unit) видом `()`.

Рукопись в приложении 20-14 собирается, но пока не создаст ни одного потока. Мы изменили определение `ThreadPool` так, чтобы он содержал вектор образцов `thread::JoinHandle<()>`, объявляли вектор ёмкостью `size`, установили круговорот `for`, который будет выполнять некоторую рукопись для создания потоков, и вернули образец данных `ThreadPool`, содержащий их.

<span class="filename">Файл: src/lib.rs</span>

```rust,ignore,not_desired_behavior
{{#rustdoc_include ../listings/ch20-web-server/listing-20-14/src/lib.rs:here}}
```

<span class="caption">Приложение 20-14: Создание вектора в <code>ThreadPool</code> для хранения потоков</span>

Мы включили `std::thread` в область видимости библиотечного ящика, потому что мы используем `thread::JoinHandle` в качестве вида переменных вектора в `ThreadPool`.

После получения правильного значения size, наш `ThreadPool` создаёт новый вектор, который может содержать `size` переменных. Функция `with_capacity` выполняет ту же задачу, что и `Vec::new`, но с важным отличием: она заранее выделяет необходимый размер памяти в векторе. Поскольку мы знаем, что нам нужно хранить `size` переменных в векторе, предварительное выделение памяти для этих переменных будет немного более производительным, чем использование `Vec::new`, при котором размер вектора будет увеличиваться по мере вставки переменных.

Если вы снова запустите приказ `cargo check`, она должна завершиться успешно.

#### Стопка `Worker`, ответственная за отправку рукописи из `ThreadPool` в поток

Мы целенаправленно оставили примечание в круговороте `for` в Приложении 20-14 по поводу создания потоков. Сейчас мы разберёмся, как на самом деле создаются потоки. Обычная библиотека предоставляет `thread::spawn` для создания потоков, причём `thread::spawn` ожидает получить некоторое указание, которое поток должен использовать, как только он будет создан. Однако в нашем случае мы хотим создавать потоки и заставлять их *ожидать* указание, которое мы будем передавать им позже. Выполнение потоков во встроенной библиотеке не предоставляет никакого способа сделать это самостоятельно, мы должны сделать это вручную.

Мы будем использовать это поведение, добавив новую стопку между видом данных `ThreadPool` и потоками, которая будет управлять этим новым поведением. Мы назовём эту стопку <code>Worker</code> ("работник"), это общепринятое имя в выполнении объединений. Работник берёт рукопись, которую нужно использовать, и запускает эту рукопись внутри рабочего потока. Представьте людей, работающих на кухне ресторана: работники ожидают, пока не поступят заказы от конечных потребителей, а затем они несут ответственность за принятие этих заказов и их выполнение.

Вместо того чтобы хранить вектор образцов `JoinHandle<()>` в объединении потоков, мы будем хранить образцы стопки `Worker`. Каждый `Worker` будет хранить один образец данных `JoinHandle<()>`. Затем мы выполняем способ у `Worker`, который будет принимать замыкание и отправлять его в существующий поток для выполнения. Для того чтобы мы могли различать работники в объединении при записей действий или отладке, мы также присвоим каждому работнику `id`.

Вот как выглядит новая последовательность действий, которые будут происходить при создании `ThreadPool`. Мы выполняем рукопись, которая будет отправлять замыкание в поток, после того, как у нас будет `Worker` , заданный следующим образом:

1. Определим стопку `Worker`, которая содержит `id` и `JoinHandle<()>`.
2. Изменим `ThreadPool`, чтобы он содержал вектор образцов `Worker`.
3. Определим функцию `Worker::new`, которая принимает номер `id` и возвращает образец данных `Worker`, который содержит `id` и поток, порождённый с пустым замыканием.
4. В `ThreadPool::new` используем счётчик круговорота `for` для создания `id`, создаём новый `Worker` с этим `id` и сохраняем образец "работника" в вектор.

Если вы готовы принять вызов, попробуйте сделать эти изменения самостоятельно, не глядя на рукопись в приложении 20-15.

Готовы? Вот приложение 20-15 с одним из способов сделать указанные ранее изменения.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-15/src/lib.rs:here}}
```

<span class="caption">Приложение 20-15: Изменение <code>ThreadPool</code> для хранения образцов <code>Worker</code> вместо непосредственного хранения потоков</span>

Мы изменили название поля в `ThreadPool` с `threads` на `workers`, поскольку теперь оно содержит образцы `Worker` вместо образцов `JoinHandle<()>`. Мы используем счётчик в круговороте `for` для передачи цифрового определителя в качестве переменной `Worker::new`, и сохраняем каждый новый `Worker` в векторе с именем `workers`.

Внешняя рукопись (вроде нашего отдельного вычислителя в *src/bin/main.rs*) не обязательно должна знать подробности выполнения, касающиеся использования стопки `Worker` внутри вида данных `ThreadPool`, поэтому мы делаем стопку `Worker` и её функцию `new` закрытыми. Функция `Worker::new` использует заданный нами `id` и сохраняет образец данных `JoinHandle<()>`, который создаётся при порождении нового потока с пустым замыканием.

>  Примечание: Если операционная система не может создать поток из-за нехватки системных мощностей, `thread::spawn` со сбоем завершится. Это приведёт к завершению со сбоем нашего отдельного вычислителя целиком, даже если некоторые потоки были созданы успешно. Для простоты будем считать, что нас устраивает такое поведение, но в существующей выполнения объединения потоков вы, вероятно, захотите использовать [`std::thread::Builder`]<!-- ignore --> и его способ [`spawn`]<!-- ignore -->, который вместо этого возвращает `Result` .
>

Эта рукопись собирается и будет хранить количество образцов `Worker`, которое мы указали в качестве переменной функции `ThreadPool::new`. Но мы всё *ещё* не обрабатываем замыкание, которое мы получаем в способе `execute`. Давайте посмотрим, как это сделать далее.

#### Отправка запросов в потоки через потоки

Следующая неполадка, с которой мы будем бороться, заключается в том, что замыкания, переданные в `thread::spawn` безусловно ничего не делают. Сейчас мы получаем замыкание, которое хотим выполнить, в способе `execute`. Но мы должны передать какое-то замыкание в способ `thread::spawn`, при создании каждого `Worker`  во время создания `ThreadPool`.

Мы хотим, чтобы вновь созданные стопки `Worker` извлекали рукопись для запуска из очереди, хранящейся в `ThreadPool` и отправляли эту рукопись в свой поток для выполнения.

потоки (channels), простой способ связи между двумя потоками, с которыми мы познакомились в главе 16, кажется наилучше подойдут для этого задумки. Мы будем использовать поток в качестве очереди заданий, а приказ `execute` отправит задание из `ThreadPool` образцам <code>Worker</code>, которые будут отправлять задание в свой поток. Расчет таков:

1. `ThreadPool` создаст поток и будет хранить отправитель.
2. Каждый `Worker` будет хранить приёмник.
3. Мы создадим новую стопку `Job`, которое будет хранить замыкания, которые мы хотим отправить в поток.
4. Способ `execute` отправит задание, которое он хочет выполнить, в отправляющую сторону потока.
5. В своём потоке `Worker` будет замкнуто опрашивать принимающую сторону потока и выполнять замыкание любого задания, которое он получит.

Давайте начнём с создания потока в `ThreadPool::new` и удержания отправляющей стороны в образце `ThreadPool`, как показано в приложении 20-16. В стопке `Job` сейчас ничего не содержится, но это будет вид переменной, которую мы отправляем в поток.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-16/src/lib.rs:here}}
```

<span class="caption">Приложение 20-16: Изменение <code>ThreadPool</code> для хранения отправляющей части потока, который отправляет образцы <code>Job</code></span>

В `ThreadPool::new` мы создаём наш новый поток и сохраняем в объединении его отправляющую сторону. Рукопись успешно собирается.

Давайте попробуем передавать принимающую сторону потока каждому "работнику" (стопке Worker), когда объединение потоков создаёт поток. Мы знаем, что хотим использовать получающую часть потока в потоке, порождаемым "работником", поэтому мы будем ссылаться на свойство `receiver` в замыкании. Рукопись 20-17 пока не собирается.

<span class="filename">Файл: src/lib.rs</span>

```rust,ignore,does_not_compile
{{#rustdoc_include ../listings/ch20-web-server/listing-20-17/src/lib.rs:here}}
```

<span class="caption">Приложение 20-17: Передача принимающей части потока "работникам"</span>

Мы внесли несколько небольших и простых изменений: мы передаём принимающую часть потока в `Worker::new`, а затем используем его внутри замыкания.

При попытке проверить рукопись, мы получаем ошибку:

```console
{{#include ../listings/ch20-web-server/listing-20-17/output.txt}}
```

Рукопись пытается передать `receiver` нескольким образцам `Worker`. Это не сработает, поскольку, как вы можете помнить из Главы 16: выполнение потока, которую предоставляет Ржавчина - несколько *производителей*, один *потребитель*. Это означает, что мы не можем просто удваивать принимающую сторону потока, чтобы исправить эту рукопись. Кроме этого, мы не хотим отправлять одно и то же сообщение нескольким потребителям, поэтому нам нужен единый список сообщений для множества обработчиков, чтобы каждое сообщение обрабатывалось лишь один раз.

Кроме того, удаление задачи из очереди потока включает изменение `receiver`, поэтому потокам необходим безопасный способ делиться и изменять `receiver`, в противном случае мы можем получить условия гонки (как описано в главе 16).

Вспомните умные указатели, которые обсуждались в главе 16: чтобы делиться владением между несколькими потоками и разрешать потокам изменять значение, нам нужно использовать вид данных `Arc<Mutex<T>>`. Вид данных `Arc` позволит нескольким "работникам" владеть получателем (receiver), а `Mutex` заверяет что только один "работник" сможет получить задание (job) от получателя за раз. Приложение 20-18 показывает изменения, которые мы должны сделать.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-18/src/lib.rs:here}}
```

<span class="caption">Приложение 20-18: Совместное использование приёмника в "работниках" с применением <code>Arc</code> и <code>Mutex</code></span>

В `ThreadPool::new` мы помещаем принимающую сторону потока внутрь `Arc` и `Mutex`. Для каждого нового "работника" мы удвоим `Arc`, чтобы увеличить счётчик ссылок так, что "работники" могут разделять владение принимающей стороной потока.

С этими изменениями рукопись собирается! Мы подбираемся к цели!

#### Использование способа `execute`

Давайте выполняем наконец способ `execute` у вида данных `ThreadPool`. Мы также изменим вид данных `Job` со стопки на псевдоним вида для сущность-предмета. который будет содержать вид данных замыкания, принимаемый способом `execute`. Как описано в разделе ["Создание родственных видов с помощью псевдонимов вида данных"](ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases)<!-- ignore --> Главы 19, псевдонимы видов данных позволяют делать длинные виды данных короче, облегчая их использование. Посмотрите на приложение 20-19.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-19/src/lib.rs:here}}
```

<span class="caption">Приложение 20-19: Создание псевдонима вида данных <code>Job</code> для указателя <code>Box</code>, содержащего каждое замыкание и затем отправляющее задание (job) в поток</span>

После создания нового образца данных `Job` с замыканием, полученным в `execute`, мы посылаем его через отправляющий конец потока. На тот случай, если отправка не удастся, вызываем `unwrap` у `send`. Это может произойти, например, если мы остановим выполнение всех наших потоков, что означает, что принимающая сторона прекратила получать новые сообщения. На данное мгновение мы не можем остановить выполнение наших потоков: наши потоки будут исполняться до тех пор, пока существует объединение Причина, по которой мы используем `unwrap`, заключается в том, что, хотя мы знаем, что сбой не произойдёт, сборщик этого не знает.

Но мы ещё не закончили! В "работнике" (worker) наше замыкание, переданное в `thread::spawn` все ещё *ссылается* только на принимающую сторону потока. Вместо этого нам нужно, чтобы замыкание работало в бесконечном круговороте, запрашивая задание у принимающей части потока и выполняя задание, когда оно принято. Давайте внесём изменения, показанные в приложении 20-20 внутри `Worker::new`.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-20/src/lib.rs:here}}
```

<span class="caption">Приложение 20-20: Получение и выполнение заданий в потоке "работника"</span>

Здесь мы сначала вызываем `lock` у `receiver`, чтобы получить взаимное исключение, а затем вызываем `unwrap`, чтобы со сбоем завершить работу при любых ошибках. Захват запрета может завершиться неудачей, если взаимное исключение находится в *отравленном* состоянии (poisoned state), что может произойти, если какой-то другой поток завершился со сбоем, удерживая запрет, вместо снятия запрета. В этой случае вызвать `unwrap` для со сбоем завершения потока вполне оправдано. Не стесняйтесь заменить `unwrap` на `expect` с сообщением об ошибке, которое имеет для вас значение.

Если мы получили запрет взаимного исключения, мы вызываем `recv`, чтобы получить `Job` из потока. Последний вызов `unwrap` позволяет миновать любые ошибки, которые могут возникнуть, если поток, управляющий отправитель, прекратил исполняться, подобно тому, как способ `send` возвращает `Err`, если получатель не принимает сообщение.

Вызов `recv` - запрещающий, поэтому пока задач нет, текущий поток будет ждать, пока задача не появится. `Mutex<T>` заверяет, что только один поток `Worker` за раз попытается запросить задачу.

Наш объединение потоков теперь находится в рабочем состоянии! Выполните `cargo run` и сделайте несколько запросов:

<!-- manual-regeneration
cd listings/ch20-web-server/listing-20-20
cargo run
make some requests to 127.0.0.1:7878
Can't automate because the output depends on making requests
-->

```console
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
warning: field is never read: `workers`
 --> src/lib.rs:7:5
  |
7 |     workers: Vec<Worker>,
  |     ^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: field is never read: `id`
  --> src/lib.rs:48:5
   |
48 |     id: usize,
   |     ^^^^^^^^^

warning: field is never read: `thread`
  --> src/lib.rs:49:5
   |
49 |     thread: thread::JoinHandle<()>,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: `hello` (lib) generated 3 warnings
    Finished dev [unoptimized + debuginfo] target(s) in 1.40s
     Running `target/debug/hello`
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
Worker 0 got a job; executing.
Worker 2 got a job; executing.
```

Успех! Теперь у нас есть объединение потоков, который обрабатывает соединения не согласованно. Никогда не создаётся более четырёх потоков, поэтому наша система не будет перегружена, если отдельный вычислитель получит много запросов. Если мы отправим запрос источника */sleep*, отдельный вычислитель сможет обслуживать другие запросы, обрабатывая их в другом потоке.

> Примечание: если вы запросите */sleep* в нескольких окнах обозревателя одновременно, они могут загружаться по одному, с интервалами в 5 секунд. Некоторые сетевые-обозреватели выполняют несколько образцов одного и того же запроса последовательно из-за кэширования. Такое ограничение не связано с работой нашего сетевого-отдельного вычислителя.

После изучения круговорота `while let` в главе 18 вы можете удивиться, почему мы не написали рукопись рабочего потока (worker thread), как показано в приложении 20-22.

<span class="filename">Файл: src/lib.rs</span>

```rust,ignore,not_desired_behavior
{{#rustdoc_include ../listings/ch20-web-server/listing-20-21/src/lib.rs:here}}
```

<span class="caption">Приложение 20-22: Иное выполнение <code>Worker::new</code> с использованием <code>while let</code></span>

Эта рукопись собирается и запускается, но не даёт желаемого поведения: медленный запрос всё равно приведёт к тому, что другие запросы будут ждать обработки. Причина здесь несколько тоньше: устройство `Mutex` не имеет открытого способа `unlock`, так как владение запретом основано на времени жизни `MutexGuard<T>` внутри `LockResult<MutexGuard<T>>`, которое возвращает способ `lock`. Во время сборки оценщик заимствований может проследить за выполнением правила, согласно которому к источнику, охраняемому `Mutex`, нельзя получить доступ пока мы удерживаем запрет. Однако в этой выполнение мы также можем получить случай, когда запрет будет удерживаться дольше, чем предполагалось, если мы не будем внимательно учитывать время жизни `MutexGuard<T>`.

Рукопись в приложении 20-20, использующий `let job = receiver.lock().unwrap().recv().unwrap();` работает, потому что при использовании `let` любые промежуточные значения, используемые в выражении справа от знака равенства, немедленно уничтожаются после завершения указания `let`. Однако `while let` (и `if let` и `match`) не удаляет временные значения до конца связанного раздела. Таким образом, в приложении 20-21 запрет не снимается в течение всего времени вызова `job()`, что означает, что другие работники не могут получать задания.


["Целочисленные виды данных"]: ch03-02-data-types.html#integer-types
[`std::thread::Builder`]: ../std/thread/struct.Builder.html
[`spawn`]: ../std/thread/struct.Builder.html#method.spawn